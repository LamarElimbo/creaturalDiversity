{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creature Catcher (Web Scrape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set up data collection foundation\n",
    "\n",
    "CREATURE_NAME=[]\n",
    "CREATURE_CAT=[]\n",
    "SEASON_NUM=[]\n",
    "SHOW_NAME=[]\n",
    "\n",
    "TABLE_COLUMNS = ['creature_name', 'creature_cat', 'season_num', 'show_name']\n",
    "\n",
    "DATABASE = {'creature_name':CREATURE_NAME, 'creature_cat':CREATURE_CAT, 'season_num':SEASON_NUM, 'show_name':SHOW_NAME}\n",
    "\n",
    "SUPERNATURAL_URL = 'http://supernatural.wikia.com/wiki/Category:Creatures?page='\n",
    "BUFFY_URL = 'http://buffy.wikia.com/wiki/Category:Creatures'\n",
    "CHARMED_URL = 'http://charmed.wikia.com/wiki/Category:Magical_beings'\n",
    "GRIMM_URL = 'http://grimm.wikia.com/wiki/Wesen'\n",
    "\n",
    "categoryLinks = []\n",
    "creatureLinks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd\n",
    "import re\n",
    "from urllib import request\n",
    "\n",
    "# Convert html to a more user friendly format\n",
    "def soupTheLink(url):\n",
    "    html = request.urlopen(url).read().decode('utf8')\n",
    "    return soup(html, 'lxml')\n",
    "\n",
    "# Collect a list of links to the categories of creatures\n",
    "def collectCatLinks(url):\n",
    "    souped = soupTheLink(url)\n",
    "\n",
    "    for subcategories in souped.find_all(id='mw-subcategories'):\n",
    "        for gallery in subcategories.find_all(class_='category-gallery-room1'):\n",
    "            for listItem in gallery.find_all(class_='category-gallery-item'):\n",
    "                link = listItem.find('a', href = True)\n",
    "                try:\n",
    "                    fullLink = link['href']\n",
    "                    categoryLinks.append(fullLink)\n",
    "                except TypeError:\n",
    "                    pass\n",
    "        \n",
    "def findNumPages(url):\n",
    "    souped = soupTheLink(url)\n",
    "    pages = 0\n",
    "    for subcategories in souped.find_all(id='mw-subcategories'):\n",
    "        for pagination in subcategories.find_all(class_='wikia-paginator'):\n",
    "            for listItem in pagination.find_all('li'):\n",
    "                pages += 1\n",
    "    return pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://supernatural.wikia.com/wiki/Category:Creatures?page=1\n",
      "['http://supernatural.wikia.com/wiki/Category:Angels', 'http://supernatural.wikia.com/wiki/Category:Strongest_of_Species', 'http://supernatural.wikia.com/wiki/Category:Deities', 'http://supernatural.wikia.com/wiki/Category:Monster', 'http://supernatural.wikia.com/wiki/Category:Demons', 'http://supernatural.wikia.com/wiki/Category:One-Episode_Species', 'http://supernatural.wikia.com/wiki/Category:Witches', 'http://supernatural.wikia.com/wiki/Category:God%27s_creations', 'http://supernatural.wikia.com/wiki/Category:Vampires', 'http://supernatural.wikia.com/wiki/Category:Hybrid', 'http://supernatural.wikia.com/wiki/Category:Higher_Beings', 'http://supernatural.wikia.com/wiki/Category:Constructs', 'http://supernatural.wikia.com/wiki/Category:Ghosts', 'http://supernatural.wikia.com/wiki/Category:Shapeshifter', 'http://supernatural.wikia.com/wiki/Category:Alpha', 'http://supernatural.wikia.com/wiki/Category:Amazons']\n",
      "http://supernatural.wikia.com/wiki/Category:Creatures?page=2\n",
      "['http://supernatural.wikia.com/wiki/Category:Angels', 'http://supernatural.wikia.com/wiki/Category:Strongest_of_Species', 'http://supernatural.wikia.com/wiki/Category:Deities', 'http://supernatural.wikia.com/wiki/Category:Monster', 'http://supernatural.wikia.com/wiki/Category:Demons', 'http://supernatural.wikia.com/wiki/Category:One-Episode_Species', 'http://supernatural.wikia.com/wiki/Category:Witches', 'http://supernatural.wikia.com/wiki/Category:God%27s_creations', 'http://supernatural.wikia.com/wiki/Category:Vampires', 'http://supernatural.wikia.com/wiki/Category:Hybrid', 'http://supernatural.wikia.com/wiki/Category:Higher_Beings', 'http://supernatural.wikia.com/wiki/Category:Constructs', 'http://supernatural.wikia.com/wiki/Category:Ghosts', 'http://supernatural.wikia.com/wiki/Category:Shapeshifter', 'http://supernatural.wikia.com/wiki/Category:Alpha', 'http://supernatural.wikia.com/wiki/Category:Amazons', 'http://supernatural.wikia.com/wiki/Category:Amazons', 'http://supernatural.wikia.com/wiki/Category:Familiar', 'http://supernatural.wikia.com/wiki/Category:Leviathans', 'http://supernatural.wikia.com/wiki/Category:Reaper', 'http://supernatural.wikia.com/wiki/Category:Werewolves', 'http://supernatural.wikia.com/wiki/Category:Fairies', 'http://supernatural.wikia.com/wiki/Category:Horseman', 'http://supernatural.wikia.com/wiki/Category:Zanna']\n"
     ]
    }
   ],
   "source": [
    "numPages = findNumPages(SUPERNATURAL_URL) - 1\n",
    "for i in range(1,numPages):\n",
    "    url = SUPERNATURAL_URL + str(i)\n",
    "    print(url)\n",
    "    \n",
    "    collectCatLinks(url)\n",
    "    print(categoryLinks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "link:  h\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "unknown url type: 'h'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-089523145510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreatureLinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mcollectCreatureLinks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-089523145510>\u001b[0m in \u001b[0;36mcollectCreatureLinks\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcreatureLinks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mnumPages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfindNumCreaturePages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumPages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlink\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0;34m'?page='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-089523145510>\u001b[0m in \u001b[0;36mfindNumCreaturePages\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfindNumCreaturePages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0msouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoupTheLink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msubcategories\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mw-pages'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-2800a5fde0af>\u001b[0m in \u001b[0;36msoupTheLink\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Convert html to a more user friendly format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msoupTheLink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mhtml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lxml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0;31m# accept a URL or a Request object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullurl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfullurl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfullurl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, url, data, headers, origin_req_host, unverifiable, method)\u001b[0m\n\u001b[1;32m    267\u001b[0m                  \u001b[0morigin_req_host\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munverifiable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                  method=None):\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munredirected_hdrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mfull_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfragment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplittag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeleter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    322\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplittype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_full_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown url type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplithost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unknown url type: 'h'"
     ]
    }
   ],
   "source": [
    "def collectCreatureLinks():\n",
    "    for mainLink in categoryLinks:\n",
    "        \n",
    "        def findCategory(url):\n",
    "            category = str(url[44:])\n",
    "            DATABASE['creature_cat'].append(category)\n",
    "        \n",
    "        def findNumCreaturePages(url):\n",
    "            souped = soupTheLink(url)\n",
    "            pages = 0\n",
    "            for subcategories in souped.find_all(id='mw-pages'):\n",
    "                for pagination in subcategories.find_all(class_='wikia-paginator'):\n",
    "                    for listItem in pagination.find_all('li'):\n",
    "                        pages += 1\n",
    "            return pages\n",
    "        \n",
    "        def collectLinks(url):\n",
    "            souped = soupTheLink(url)\n",
    "\n",
    "            for subcategories in souped.find_all(id='mw-pages'):\n",
    "                for listItem in subcategories.find_all(class_='category-gallery-item'):\n",
    "                    link = listItem.find('a', href = True)\n",
    "                    try:\n",
    "                        fullLink = link['href']\n",
    "                        creatureLinks.append(fullLink)\n",
    "                    except TypeError:\n",
    "                        pass\n",
    "                    findCategory(mainLink)\n",
    "                return creatureLinks\n",
    "\n",
    "        numPages = findNumCreaturePages(mainLink) - 1\n",
    "        for i in range(1,numPages):\n",
    "            url = mainLink  + '?page=' + str(i)\n",
    "            print(url)\n",
    "\n",
    "            collectLinks(url)\n",
    "            print(creatureLinks)\n",
    "\n",
    "collectCreatureLinks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of creatures =  89\n",
      "creature number  1\n",
      "creature number  2\n",
      "creature number  3\n",
      "creature number  4\n",
      "creature number  5\n",
      "{'creature_name': ['Castiel', 'Lucifer', 'Gabriel', 'Michael', 'Angels'], 'season_num': [[4], [4], [2], [5], 'None'], 'show_name': ['Supernatural', 'Supernatural', 'Supernatural', 'Supernatural', 'Supernatural'], 'creature_cat': ['Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels', 'Angels']}\n"
     ]
    }
   ],
   "source": [
    "def compileData(listOfCreatureLinks):\n",
    "    print(\"number of creatures = \", len(listOfCreatureLinks))\n",
    "    count = 0\n",
    "    for url in listOfCreatureLinks[:5]:\n",
    "        count += 1\n",
    "        print('creature number ', count)\n",
    "        souped = soupTheLink(url)\n",
    "        \n",
    "        #collect creature name\n",
    "        name = url[35:]\n",
    "        DATABASE['creature_name'].append(name)\n",
    "        \n",
    "        #collect show name\n",
    "        DATABASE['show_name'].append('Supernatural')\n",
    "        \n",
    "        #collect season appearances\n",
    "        for table in souped.find_all(id='mw-content-text'):\n",
    "            SEASON_NUM=[]\n",
    "            for body in table.find_all('table'):\n",
    "                for row in body.find_all('tr'):\n",
    "                    season = row.find('a', href = True)\n",
    "                    try:\n",
    "                        seasons = season['href']\n",
    "                        seasons = str(seasons)\n",
    "                        if seasons[:13] == '/wiki/Season_':\n",
    "                            SEASON_NUM.append(int(seasons[13:]))\n",
    "                    except TypeError:\n",
    "                        pass\n",
    "            if SEASON_NUM == []:\n",
    "                DATABASE['season_num'].append('None')   \n",
    "            else:\n",
    "                DATABASE['season_num'].append(SEASON_NUM)   \n",
    "\n",
    "\n",
    "\n",
    "compileData(creatureLinks)\n",
    "print(DATABASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
